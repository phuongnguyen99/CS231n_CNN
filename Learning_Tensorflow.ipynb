{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phuongnguyen99/CS231n_CNN/blob/main/Learning_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO7e2JLE2dB-",
        "outputId": "1ef56deb-66ee-4dd8-ddc1-81376daf02ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "USE_GPU = True\n",
        "\n",
        "if USE_GPU:\n",
        "    device = '/device:GPU:0'\n",
        "else:\n",
        "    device = '/cpu:0'\n",
        "\n",
        "# Constant to control how often we print when training models.\n",
        "print_every = 100\n",
        "print('Using device: ', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD1pQ7ax_fZN",
        "outputId": "fd293d22-dde5-428c-d17d-c09333ca52ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
        "    \"\"\"\n",
        "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
        "    it for the two-layer neural net classifier. These are the same steps as\n",
        "    we used for the SVM, but condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
        "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\n",
        "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\n",
        "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = range(num_training, num_training + num_validation)\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean pixel and divide by std\n",
        "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "    X_train = (X_train - mean_pixel) / std_pixel\n",
        "    X_val = (X_val - mean_pixel) / std_pixel\n",
        "    X_test = (X_test - mean_pixel) / std_pixel\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# If there are errors with SSL downloading involving self-signed certificates,\n",
        "# it may be that your Python version was recently installed on the current machine.\n",
        "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
        "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
        "#   ...replacing paths as necessary.\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "NHW = (0, 1, 2)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuc0R3u9_b68",
        "outputId": "a67b0c7a-fba8-4928-f2d4-1d8407c1ae3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n",
            "Train data shape:  (49000, 32, 32, 3)\n",
            "Train labels shape:  (49000,) int32\n",
            "Validation data shape:  (1000, 32, 32, 3)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (10000, 32, 32, 3)\n",
            "Test labels shape:  (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, X, y, batch_size, shuffle=False):\n",
        "        \"\"\"\n",
        "        Construct a Dataset object to iterate over data X and labels y\n",
        "        \n",
        "        Inputs:\n",
        "        - X: Numpy array of data, of any shape\n",
        "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
        "        - batch_size: Integer giving number of elements per minibatch\n",
        "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
        "        \"\"\"\n",
        "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
        "        self.X, self.y = X, y\n",
        "        self.batch_size, self.shuffle = batch_size, shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        N, B = self.X.shape[0], self.batch_size\n",
        "        idxs = np.arange(N)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(idxs)\n",
        "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
        "\n",
        "\n",
        "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
        "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
        "test_dset = Dataset(X_test, y_test, batch_size=64)"
      ],
      "metadata": {
        "id": "qeEfuytQAuHH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can iterate through a dataset like this:\n",
        "for t, (x, y) in enumerate(train_dset):\n",
        "    print(t, x.shape, y.shape)\n",
        "    if t > 5: break\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLuAMTntCKsV",
        "outputId": "a0da3988-1a64-46ce-b538-33389f90bb78"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (64, 32, 32, 3) (64,)\n",
            "1 (64, 32, 32, 3) (64,)\n",
            "2 (64, 32, 32, 3) (64,)\n",
            "3 (64, 32, 32, 3) (64,)\n",
            "4 (64, 32, 32, 3) (64,)\n",
            "5 (64, 32, 32, 3) (64,)\n",
            "6 (64, 32, 32, 3) (64,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(x):\n",
        "    \"\"\"    \n",
        "    Input:\n",
        "    - TensorFlow Tensor of shape (N, D1, ..., DM)\n",
        "    \n",
        "    Output:\n",
        "    - TensorFlow Tensor of shape (N, D1 * ... * DM)\n",
        "    \"\"\"\n",
        "    N = tf.shape(x)[0]\n",
        "    return tf.reshape(x, (N, -1))"
      ],
      "metadata": {
        "id": "RCLXkO51DusF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_flatten():\n",
        "    # Construct concrete values of the input data x using numpy\n",
        "    x_np = np.arange(24).reshape((2, 3, 4))\n",
        "    print('x_np:\\n', x_np, '\\n')\n",
        "    # Compute a concrete output value.\n",
        "    x_flat_np = flatten(x_np)\n",
        "    print('x_flat_np:\\n', x_flat_np, '\\n')\n",
        "\n",
        "test_flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFWuwyUjDxWt",
        "outputId": "8e1b0149-588a-4d8c-9448-9b3c7dd7eb65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_np:\n",
            " [[[ 0  1  2  3]\n",
            "  [ 4  5  6  7]\n",
            "  [ 8  9 10 11]]\n",
            "\n",
            " [[12 13 14 15]\n",
            "  [16 17 18 19]\n",
            "  [20 21 22 23]]] \n",
            "\n",
            "x_flat_np:\n",
            " tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17 18 19 20 21 22 23]], shape=(2, 12), dtype=int64) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def two_layer_fc(x, params):\n",
        "    \"\"\"\n",
        "    A fully-connected neural network; the architecture is:\n",
        "    fully-connected layer -> ReLU -> fully connected layer.\n",
        "    Note that we only need to define the forward pass here; TensorFlow will take\n",
        "    care of computing the gradients for us.\n",
        "    \n",
        "    The input to the network will be a minibatch of data, of shape\n",
        "    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n",
        "    and the output layer will produce scores for C classes.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A TensorFlow Tensor of shape (N, d1, ..., dM) giving a minibatch of\n",
        "      input data.\n",
        "    - params: A list [w1, w2] of TensorFlow Tensors giving weights for the\n",
        "      network, where w1 has shape (D, H) and w2 has shape (H, C).\n",
        "    \n",
        "    Returns:\n",
        "    - scores: A TensorFlow Tensor of shape (N, C) giving classification scores\n",
        "      for the input data x.\n",
        "    \"\"\"\n",
        "    w1, w2 = params                   # Unpack the parameters\n",
        "    x = flatten(x)                    # Flatten the input; now x has shape (N, D)\n",
        "    h = tf.nn.relu(tf.matmul(x, w1))  # Hidden layer: h has shape (N, H)\n",
        "    scores = tf.matmul(h, w2)         # Compute scores of shape (N, C)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "cdFyTa2xFejx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def two_layer_fc_test():\n",
        "    hidden_layer_size = 42\n",
        "\n",
        "    # Scoping our TF operations under a tf.device context manager \n",
        "    # lets us tell TensorFlow where we want these Tensors to be\n",
        "    # multiplied and/or operated on, e.g. on a CPU or a GPU.\n",
        "    with tf.device(device):        \n",
        "        x = tf.zeros((64, 32, 32, 3))\n",
        "        w1 = tf.zeros((32 * 32 * 3, hidden_layer_size))\n",
        "        w2 = tf.zeros((hidden_layer_size, 10))\n",
        "\n",
        "        # Call our two_layer_fc function for the forward pass of the network.\n",
        "        scores = two_layer_fc(x, [w1, w2])\n",
        "\n",
        "    print(scores.shape)\n",
        "\n",
        "two_layer_fc_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDedDS73Fhw_",
        "outputId": "e7e12cee-35d1-44eb-d75e-b1c000a6718c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def three_layer_convnet(x, params):\n",
        "    \"\"\"\n",
        "    A three-layer convolutional network with the architecture described above.\n",
        "    \n",
        "    Inputs:\n",
        "    - x: A TensorFlow Tensor of shape (N, H, W, 3) giving a minibatch of images\n",
        "    - params: A list of TensorFlow Tensors giving the weights and biases for the\n",
        "      network; should contain the following:\n",
        "      - conv_w1: TensorFlow Tensor of shape (KH1, KW1, 3, channel_1) giving\n",
        "        weights for the first convolutional layer.\n",
        "      - conv_b1: TensorFlow Tensor of shape (channel_1,) giving biases for the\n",
        "        first convolutional layer.\n",
        "      - conv_w2: TensorFlow Tensor of shape (KH2, KW2, channel_1, channel_2)\n",
        "        giving weights for the second convolutional layer\n",
        "      - conv_b2: TensorFlow Tensor of shape (channel_2,) giving biases for the\n",
        "        second convolutional layer.\n",
        "      - fc_w: TensorFlow Tensor giving weights for the fully-connected layer.\n",
        "        Can you figure out what the shape should be?\n",
        "      - fc_b: TensorFlow Tensor giving biases for the fully-connected layer.\n",
        "        Can you figure out what the shape should be?\n",
        "    \"\"\"\n",
        "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
        "    scores = None\n",
        "    ############################################################################\n",
        "    # TODO: Implement the forward pass for the three-layer ConvNet.            #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    x_padded = tf.pad(x,[[0,0],[2,2],[2,2],[0,0]],'CONSTANT')\n",
        "    conv1 = tf.nn.conv2d(x_padded, conv_w1,[1,1,1,1], padding = 'VALID') + conv_b1\n",
        "    relu_c1 = tf.nn.relu(conv1)\n",
        "    x_padded_c2 = tf.pad(relu_c1,[[0,0],[1,1],[1,1],[0,0]],'CONSTANT')\n",
        "    conv2 = tf.nn.conv2d(x_padded_c2, conv_w2,[1,1,1,1], padding = 'VALID') + conv_b2\n",
        "    relu_c2 = tf.nn.relu(conv2)\n",
        "    relu_flatten = flatten(relu_c2)\n",
        "    scores = tf.matmul(relu_flatten, fc_w) +fc_b\n",
        "\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                              END OF YOUR CODE                            #\n",
        "    ############################################################################\n",
        "    return scores"
      ],
      "metadata": {
        "id": "g-EzMKumMORO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def three_layer_convnet_test():\n",
        "    \n",
        "    with tf.device(device):\n",
        "        x = tf.zeros((64, 32, 32, 3))\n",
        "        conv_w1 = tf.zeros((5, 5, 3, 6))\n",
        "        conv_b1 = tf.zeros((6,))\n",
        "        conv_w2 = tf.zeros((3, 3, 6, 9))\n",
        "        conv_b2 = tf.zeros((9,))\n",
        "        fc_w = tf.zeros((32 * 32 * 9, 10))\n",
        "        fc_b = tf.zeros((10,))\n",
        "        params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
        "        scores = three_layer_convnet(x, params)\n",
        "\n",
        "    # Inputs to convolutional layers are 4-dimensional arrays with shape\n",
        "    # [batch_size, height, width, channels]\n",
        "    print('scores_np has shape: ', scores.shape)\n",
        "\n",
        "three_layer_convnet_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQeD2nHsMRCZ",
        "outputId": "989a7bcf-28e3-49d1-b164-d6d031733d81"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scores_np has shape:  (64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model_fn, x, y, params, learning_rate):\n",
        "    with tf.GradientTape() as tape:\n",
        "        scores = model_fn(x, params) # Forward pass of the model\n",
        "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
        "        total_loss = tf.reduce_mean(loss)\n",
        "        grad_params = tape.gradient(total_loss, params)\n",
        "\n",
        "        # Make a vanilla gradient descent step on all of the model parameters\n",
        "        # Manually update the weights using assign_sub()\n",
        "        for w, grad_w in zip(params, grad_params):\n",
        "            w.assign_sub(learning_rate * grad_w)\n",
        "                        \n",
        "        return total_loss"
      ],
      "metadata": {
        "id": "WC-vZnvWUfG1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(dset, x, model_fn, params):\n",
        "    \"\"\"\n",
        "    Check accuracy on a classification model, e.g. for validation.\n",
        "    \n",
        "    Inputs:\n",
        "    - dset: A Dataset object against which to check accuracy\n",
        "    - x: A TensorFlow placeholder Tensor where input images should be fed\n",
        "    - model_fn: the Model we will be calling to make predictions on x\n",
        "    - params: parameters for the model_fn to work with\n",
        "      \n",
        "    Returns: Nothing, but prints the accuracy of the model\n",
        "    \"\"\"\n",
        "    num_correct, num_samples = 0, 0\n",
        "    for x_batch, y_batch in dset:\n",
        "        scores_np = model_fn(x_batch, params).numpy()\n",
        "        y_pred = scores_np.argmax(axis=1)\n",
        "        num_samples += x_batch.shape[0]\n",
        "        num_correct += (y_pred == y_batch).sum()\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
      ],
      "metadata": {
        "id": "U3odJpZuUh1I"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_part2(model_fn, init_fn, learning_rate):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10.\n",
        "    \n",
        "    Inputs:\n",
        "    - model_fn: A Python function that performs the forward pass of the model\n",
        "      using TensorFlow; it should have the following signature:\n",
        "      scores = model_fn(x, params) where x is a TensorFlow Tensor giving a\n",
        "      minibatch of image data, params is a list of TensorFlow Tensors holding\n",
        "      the model weights, and scores is a TensorFlow Tensor of shape (N, C)\n",
        "      giving scores for all elements of x.\n",
        "    - init_fn: A Python function that initializes the parameters of the model.\n",
        "      It should have the signature params = init_fn() where params is a list\n",
        "      of TensorFlow Tensors holding the (randomly initialized) weights of the\n",
        "      model.\n",
        "    - learning_rate: Python float giving the learning rate to use for SGD.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    params = init_fn()  # Initialize the model parameters            \n",
        "        \n",
        "    for t, (x_np, y_np) in enumerate(train_dset):\n",
        "        # Run the graph on a batch of training data.\n",
        "        loss = training_step(model_fn, x_np, y_np, params, learning_rate)\n",
        "        \n",
        "        # Periodically print the loss and check accuracy on the val set.\n",
        "        if t % print_every == 0:\n",
        "            print('Iteration %d, loss = %.4f' % (t, loss))\n",
        "            check_accuracy(val_dset, x_np, model_fn, params)"
      ],
      "metadata": {
        "id": "NuJgmBveUi8A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_matrix_with_kaiming_normal(shape):\n",
        "    if len(shape) == 2:\n",
        "        fan_in, fan_out = shape[0], shape[1]\n",
        "    elif len(shape) == 4:\n",
        "        fan_in, fan_out = np.prod(shape[:3]), shape[3]\n",
        "    return tf.keras.backend.random_normal(shape) * np.sqrt(2.0 / fan_in)"
      ],
      "metadata": {
        "id": "tpKNqS8hWOZA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def two_layer_fc_init():\n",
        "    \"\"\"\n",
        "    Initialize the weights of a two-layer network, for use with the\n",
        "    two_layer_network function defined above. \n",
        "    You can use the `create_matrix_with_kaiming_normal` helper!\n",
        "    \n",
        "    Inputs: None\n",
        "    \n",
        "    Returns: A list of:\n",
        "    - w1: TensorFlow tf.Variable giving the weights for the first layer\n",
        "    - w2: TensorFlow tf.Variable giving the weights for the second layer\n",
        "    \"\"\"\n",
        "    hidden_layer_size = 4000\n",
        "    w1 = tf.Variable(create_matrix_with_kaiming_normal((3 * 32 * 32, 4000)))\n",
        "    w2 = tf.Variable(create_matrix_with_kaiming_normal((4000, 10)))\n",
        "    return [w1, w2]\n",
        "\n",
        "learning_rate = 1e-2\n",
        "train_part2(two_layer_fc, two_layer_fc_init, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j8GvY1WWQ4i",
        "outputId": "5551109e-06d3-4c19-c23f-046cb2c92669"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 3.2506\n",
            "Got 117 / 1000 correct (11.70%)\n",
            "Iteration 100, loss = 1.8461\n",
            "Got 392 / 1000 correct (39.20%)\n",
            "Iteration 200, loss = 1.5201\n",
            "Got 384 / 1000 correct (38.40%)\n",
            "Iteration 300, loss = 1.8027\n",
            "Got 380 / 1000 correct (38.00%)\n",
            "Iteration 400, loss = 1.7688\n",
            "Got 420 / 1000 correct (42.00%)\n",
            "Iteration 500, loss = 1.8658\n",
            "Got 442 / 1000 correct (44.20%)\n",
            "Iteration 600, loss = 1.8008\n",
            "Got 411 / 1000 correct (41.10%)\n",
            "Iteration 700, loss = 1.9818\n",
            "Got 457 / 1000 correct (45.70%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def three_layer_convnet_init():\n",
        "    \"\"\"\n",
        "    Initialize the weights of a Three-Layer ConvNet, for use with the\n",
        "    three_layer_convnet function defined above.\n",
        "    You can use the `create_matrix_with_kaiming_normal` helper!\n",
        "    \n",
        "    Inputs: None\n",
        "    \n",
        "    Returns a list containing:\n",
        "    - conv_w1: TensorFlow tf.Variable giving weights for the first conv layer\n",
        "    - conv_b1: TensorFlow tf.Variable giving biases for the first conv layer\n",
        "    - conv_w2: TensorFlow tf.Variable giving weights for the second conv layer\n",
        "    - conv_b2: TensorFlow tf.Variable giving biases for the second conv layer\n",
        "    - fc_w: TensorFlow tf.Variable giving weights for the fully-connected layer\n",
        "    - fc_b: TensorFlow tf.Variable giving biases for the fully-connected layer\n",
        "    \n",
        "    - params: A list of TensorFlow Tensors giving the weights and biases for the\n",
        "      network; should contain the following:\n",
        "      - conv_w1: TensorFlow Tensor of shape (KH1, KW1, 3, channel_1) giving\n",
        "        weights for the first convolutional layer.\n",
        "      - conv_b1: TensorFlow Tensor of shape (channel_1,) giving biases for the\n",
        "        first convolutional layer.\n",
        "      - conv_w2: TensorFlow Tensor of shape (KH2, KW2, channel_1, channel_2)\n",
        "        giving weights for the second convolutional layer\n",
        "      - conv_b2: TensorFlow Tensor of shape (channel_2,) giving biases for the\n",
        "        second convolutional layer.\n",
        "      - fc_w: TensorFlow Tensor giving weights for the fully-connected layer.\n",
        "        Can you figure out what the shape should be?\n",
        "      - fc_b: TensorFlow Tensor giving biases for the fully-connected layer.\n",
        "        Can you figure out what the shape should be?\n",
        "    \"\"\"\n",
        "    params = None\n",
        "    ############################################################################\n",
        "    # TODO: Initialize the parameters of the three-layer network.              #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    conv_w1 = tf.Variable(create_matrix_with_kaiming_normal([5,5,3,32]))\n",
        "    conv_b1 = tf.Variable(np.zeros([32]), dtype=tf.float32)\n",
        "    conv_w2 = tf.Variable(create_matrix_with_kaiming_normal([3,3,32,16]))\n",
        "    conv_b2 = tf.Variable(np.zeros([16]), dtype=tf.float32)\n",
        "    fc_w = tf.Variable(create_matrix_with_kaiming_normal([32*32*16, 10]))\n",
        "\n",
        "    fc_b = tf.Variable(np.zeros([10]), dtype=tf.float32)\n",
        "    params = (conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b)\n",
        "    \n",
        "\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "    return params\n",
        "\n",
        "# learning_rate = 3e-3\n",
        "train_part2(three_layer_convnet, three_layer_convnet_init, learning_rate = 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdBB6RGaaSJj",
        "outputId": "110821d8-1f71-43a8-8fe8-1eb0b873b6b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 2.5802\n",
            "Got 95 / 1000 correct (9.50%)\n",
            "Iteration 100, loss = 1.8617\n",
            "Got 350 / 1000 correct (35.00%)\n",
            "Iteration 200, loss = 1.6357\n",
            "Got 386 / 1000 correct (38.60%)\n",
            "Iteration 300, loss = 1.6495\n",
            "Got 390 / 1000 correct (39.00%)\n",
            "Iteration 400, loss = 1.7159\n",
            "Got 442 / 1000 correct (44.20%)\n",
            "Iteration 500, loss = 1.7644\n",
            "Got 451 / 1000 correct (45.10%)\n",
            "Iteration 600, loss = 1.7261\n",
            "Got 452 / 1000 correct (45.20%)\n",
            "Iteration 700, loss = 1.7186\n",
            "Got 473 / 1000 correct (47.30%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerFC(tf.keras.Model):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(TwoLayerFC, self).__init__()        \n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "    \n",
        "    def call(self, x, training=False):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = TwoLayerFC(hidden_size, num_classes)\n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "        \n",
        "test_TwoLayerFC()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLLjpbzWheEv",
        "outputId": "2820b2b0-17c4-4172-9e27-19b4d432c8df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeLayerConvNet(tf.keras.Model):\n",
        "    def __init__(self, channel_1, channel_2, num_classes):\n",
        "        super(ThreeLayerConvNet, self).__init__()\n",
        "        ########################################################################\n",
        "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
        "        # should instantiate layer objects to be used in the forward pass.     #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        initializer = tf.initializers.VarianceScaling(scale=3.0)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = channel_1, kernel_size = (5,5), strides = (1,1),\n",
        "                                          activation='relu',padding='valid',kernel_initializer=initializer)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = channel_2, kernel_size = (3,3), strides = (1,1),\n",
        "                                          activation='relu',padding='valid',kernel_initializer=initializer)\n",
        "        self.fc = tf.keras.layers.Dense(num_classes,kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.softmax = tf.keras.layers.Softmax()   \n",
        "        \n",
        "\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################\n",
        "        \n",
        "    def call(self, x, training=False):\n",
        "        scores = None\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
        "        # should use the layer objects defined in the __init__ method.         #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        x = tf.pad(x, [[0,0], [2,2], [2,2], [0,0]], 'CONSTANT')\n",
        "        x = self.conv1(x)\n",
        "        x = tf.pad(x, [[0,0], [1,1], [1,1], [0,0]], 'CONSTANT')\n",
        "        x = self.conv2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "        scores = x\n",
        "        \n",
        "\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################        \n",
        "        return scores"
      ],
      "metadata": {
        "id": "HKdGONBjq8TT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_ThreeLayerConvNet():    \n",
        "    channel_1, channel_2, num_classes = 12, 8, 10\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "    with tf.device(device):\n",
        "        x = tf.zeros((64, 3, 32, 32))\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_ThreeLayerConvNet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWx9iVZPrH3H",
        "outputId": "e170f787-d039-4971-eae7-4824299148ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
        "    \"\"\"\n",
        "    Simple training loop for use with models defined using tf.keras. It trains\n",
        "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
        "    accuracy on the CIFAR-10 validation set.\n",
        "    \n",
        "    Inputs:\n",
        "    - model_init_fn: A function that takes no parameters; when called it\n",
        "      constructs the model we want to train: model = model_init_fn()\n",
        "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
        "      constructs the Optimizer object we will use to optimize the model:\n",
        "      optimizer = optimizer_init_fn()\n",
        "    - num_epochs: The number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints progress during trainingn\n",
        "    \"\"\"    \n",
        "    with tf.device(device):\n",
        "\n",
        "        # Compute the loss like we did in Part II\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "        \n",
        "        model = model_init_fn()\n",
        "        optimizer = optimizer_init_fn()\n",
        "        \n",
        "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "    \n",
        "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "        \n",
        "        t = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            \n",
        "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
        "            train_loss.reset_states()\n",
        "            train_accuracy.reset_states()\n",
        "            \n",
        "            for x_np, y_np in train_dset:\n",
        "                with tf.GradientTape() as tape:\n",
        "                    \n",
        "                    # Use the model function to build the forward pass.\n",
        "                    scores = model(x_np, training=is_training)\n",
        "                    loss = loss_fn(y_np, scores)\n",
        "      \n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                    \n",
        "                    # Update the metrics\n",
        "                    train_loss.update_state(loss)\n",
        "                    train_accuracy.update_state(y_np, scores)\n",
        "                    \n",
        "                    if t % print_every == 0:\n",
        "                        val_loss.reset_states()\n",
        "                        val_accuracy.reset_states()\n",
        "                        for test_x, test_y in val_dset:\n",
        "                            # During validation at end of epoch, training set to False\n",
        "                            prediction = model(test_x, training=False)\n",
        "                            t_loss = loss_fn(test_y, prediction)\n",
        "\n",
        "                            val_loss.update_state(t_loss)\n",
        "                            val_accuracy.update_state(test_y, prediction)\n",
        "                        \n",
        "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
        "                        print (template.format(t, epoch+1,\n",
        "                                             train_loss.result(),\n",
        "                                             train_accuracy.result()*100,\n",
        "                                             val_loss.result(),\n",
        "                                             val_accuracy.result()*100))\n",
        "                    t += 1"
      ],
      "metadata": {
        "id": "OaOrgoXVyJNE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return TwoLayerFC(hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4d-sY7EyMLU",
        "outputId": "bbf225b6-907b-4c41-ad5c-9bfc30b7b4ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.714242935180664, Accuracy: 7.8125, Val Loss: 3.073024272918701, Val Accuracy: 12.700000762939453\n",
            "Iteration 100, Epoch 1, Loss: 2.2419300079345703, Accuracy: 28.85210418701172, Val Loss: 1.9538294076919556, Val Accuracy: 37.400001525878906\n",
            "Iteration 200, Epoch 1, Loss: 2.0764684677124023, Accuracy: 32.548194885253906, Val Loss: 1.8857735395431519, Val Accuracy: 41.0\n",
            "Iteration 300, Epoch 1, Loss: 2.000739097595215, Accuracy: 34.40095520019531, Val Loss: 1.8929636478424072, Val Accuracy: 38.29999923706055\n",
            "Iteration 400, Epoch 1, Loss: 1.931082010269165, Accuracy: 36.17129135131836, Val Loss: 1.7463773488998413, Val Accuracy: 42.29999923706055\n",
            "Iteration 500, Epoch 1, Loss: 1.8873789310455322, Accuracy: 37.150699615478516, Val Loss: 1.6892452239990234, Val Accuracy: 42.69999694824219\n",
            "Iteration 600, Epoch 1, Loss: 1.8548344373703003, Accuracy: 38.09016418457031, Val Loss: 1.7050995826721191, Val Accuracy: 42.099998474121094\n",
            "Iteration 700, Epoch 1, Loss: 1.8286088705062866, Accuracy: 38.770503997802734, Val Loss: 1.658117651939392, Val Accuracy: 43.70000076293945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1, channel_2, num_classes = 32, 16, 10\n",
        "\n",
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate , momentum=0.9, nesterov= True)\n",
        "\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV4bUbnTzqXY",
        "outputId": "b3ad7051-421d-46fc-d2cc-b433f5acd8a3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.9656412601470947, Accuracy: 12.5, Val Loss: 9.084972381591797, Val Accuracy: 10.59999942779541\n",
            "Iteration 100, Epoch 1, Loss: 2.320930004119873, Accuracy: 26.670793533325195, Val Loss: 1.7614037990570068, Val Accuracy: 38.10000228881836\n",
            "Iteration 200, Epoch 1, Loss: 1.9998316764831543, Accuracy: 33.3722038269043, Val Loss: 1.5828783512115479, Val Accuracy: 45.69999694824219\n",
            "Iteration 300, Epoch 1, Loss: 1.8552477359771729, Accuracy: 37.11067199707031, Val Loss: 1.5074924230575562, Val Accuracy: 48.10000228881836\n",
            "Iteration 400, Epoch 1, Loss: 1.7522270679473877, Accuracy: 40.09507751464844, Val Loss: 1.4361681938171387, Val Accuracy: 49.900001525878906\n",
            "Iteration 500, Epoch 1, Loss: 1.678235411643982, Accuracy: 42.39021682739258, Val Loss: 1.3802752494812012, Val Accuracy: 50.19999694824219\n",
            "Iteration 600, Epoch 1, Loss: 1.628665566444397, Accuracy: 43.78119659423828, Val Loss: 1.3327404260635376, Val Accuracy: 53.39999771118164\n",
            "Iteration 700, Epoch 1, Loss: 1.5887010097503662, Accuracy: 45.009361267089844, Val Loss: 1.3697835206985474, Val Accuracy: 53.20000076293945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    input_shape = (32, 32, 3)\n",
        "    hidden_layer_size, num_classes = 4000, 10\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    layers = [\n",
        "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
        "                              kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
        "                              kernel_initializer=initializer),\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htw3KOgY0NJO",
        "outputId": "712d7163-b516-40ca-c2c6-0f6ab5ea6d25"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.0119621753692627, Accuracy: 7.8125, Val Loss: 3.011324644088745, Val Accuracy: 12.899999618530273\n",
            "Iteration 100, Epoch 1, Loss: 2.251871347427368, Accuracy: 28.217823028564453, Val Loss: 1.8919093608856201, Val Accuracy: 38.10000228881836\n",
            "Iteration 200, Epoch 1, Loss: 2.075791358947754, Accuracy: 32.105098724365234, Val Loss: 1.889932632446289, Val Accuracy: 38.400001525878906\n",
            "Iteration 300, Epoch 1, Loss: 2.003833293914795, Accuracy: 33.97529220581055, Val Loss: 1.8569828271865845, Val Accuracy: 36.599998474121094\n",
            "Iteration 400, Epoch 1, Loss: 1.9311048984527588, Accuracy: 35.816707611083984, Val Loss: 1.7388664484024048, Val Accuracy: 41.5\n",
            "Iteration 500, Epoch 1, Loss: 1.8866020441055298, Accuracy: 36.91679382324219, Val Loss: 1.653226375579834, Val Accuracy: 43.5\n",
            "Iteration 600, Epoch 1, Loss: 1.8569049835205078, Accuracy: 37.840576171875, Val Loss: 1.713360071182251, Val Accuracy: 42.29999923706055\n",
            "Iteration 700, Epoch 1, Loss: 1.8294674158096313, Accuracy: 38.57435989379883, Val Loss: 1.6347780227661133, Val Accuracy: 45.599998474121094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "-HLHSWRx0jf3",
        "outputId": "bf95b4f4-999f-4e6b-8e10-d1878c7dbb5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 [==============================] - 4s 4ms/step - loss: 1.8260 - sparse_categorical_accuracy: 0.3864 - val_loss: 1.6258 - val_sparse_categorical_accuracy: 0.4330\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.6084 - sparse_categorical_accuracy: 0.4442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6083589792251587, 0.4442000091075897]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    input_shape = (32,32,3)\n",
        "    chanel_1, chanel_2, num_classes = 32, 16, 10\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    layers = [\n",
        "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "        tf.keras.layers.Conv2D(filters = chanel_1, kernel_size = (5,5), strides = (1,1),\n",
        "                                           activation='relu',padding='same',kernel_initializer=initializer),\n",
        "        tf.keras.layers.Conv2D(filters = chanel_2, kernel_size = (3,3), strides = (1,1),\n",
        "                                          activation='relu',padding='same',kernel_initializer=initializer),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        # tf.keras.layers.Dense(filters = num_classes,kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(num_classes, kernel_initializer=initializer),\n",
        "        tf.keras.layers.Softmax()\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    return model\n",
        "    \n",
        "\n",
        "    # pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                            END OF YOUR CODE                              #\n",
        "    ############################################################################\n",
        "    # return model\n",
        "\n",
        "learning_rate = 5e-4\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum = 0.9, nesterov= True) \n",
        "\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JnIHMaeRaG3",
        "outputId": "2267a51d-fb16-45ff-eb13-7e223d1f784c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.823869228363037, Accuracy: 12.5, Val Loss: 2.6458985805511475, Val Accuracy: 10.5\n",
            "Iteration 100, Epoch 1, Loss: 1.9743764400482178, Accuracy: 30.476484298706055, Val Loss: 1.7752528190612793, Val Accuracy: 39.39999771118164\n",
            "Iteration 200, Epoch 1, Loss: 1.8500899076461792, Accuracy: 35.059078216552734, Val Loss: 1.6507887840270996, Val Accuracy: 43.29999923706055\n",
            "Iteration 300, Epoch 1, Loss: 1.7830449342727661, Accuracy: 37.32350540161133, Val Loss: 1.608421802520752, Val Accuracy: 44.80000305175781\n",
            "Iteration 400, Epoch 1, Loss: 1.7239418029785156, Accuracy: 39.32746505737305, Val Loss: 1.5467864274978638, Val Accuracy: 46.20000076293945\n",
            "Iteration 500, Epoch 1, Loss: 1.6825448274612427, Accuracy: 40.69673156738281, Val Loss: 1.5109102725982666, Val Accuracy: 47.400001525878906\n",
            "Iteration 600, Epoch 1, Loss: 1.654444694519043, Accuracy: 41.71173095703125, Val Loss: 1.4871400594711304, Val Accuracy: 49.70000076293945\n",
            "Iteration 700, Epoch 1, Loss: 1.6294344663619995, Accuracy: 42.61991500854492, Val Loss: 1.4676929712295532, Val Accuracy: 50.80000305175781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcYBoZwRWXZ7",
        "outputId": "8848ff3a-fca2-484c-f09a-987068d68ee4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 [==============================] - 4s 4ms/step - loss: 1.5874 - sparse_categorical_accuracy: 0.4407 - val_loss: 1.4037 - val_sparse_categorical_accuracy: 0.4980\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4212 - sparse_categorical_accuracy: 0.4913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4212288856506348, 0.49129998683929443]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
        "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                 kernel_initializer=initializer)(flattened_inputs)\n",
        "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                             kernel_initializer=initializer)(fc1_output)\n",
        "\n",
        "    # Instantiate the model given inputs and outputs.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
        "    return model\n",
        "\n",
        "def test_two_layer_fc_functional():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    input_shape = (50,)\n",
        "    \n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "    \n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "        \n",
        "test_two_layer_fc_functional()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLiyMJLga1zW",
        "outputId": "2af74aaf-9d99-46e2-ba74-184980de713c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32, 32, 3)\n",
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKeFPEVJbdDT",
        "outputId": "0bc18852-4a59-41fe-abd5-a4098ccf905f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.1066348552703857, Accuracy: 9.375, Val Loss: 2.8506009578704834, Val Accuracy: 14.200000762939453\n",
            "Iteration 100, Epoch 1, Loss: 2.2456891536712646, Accuracy: 28.29517364501953, Val Loss: 1.8707401752471924, Val Accuracy: 39.099998474121094\n",
            "Iteration 200, Epoch 1, Loss: 2.0742945671081543, Accuracy: 32.26057434082031, Val Loss: 1.8533170223236084, Val Accuracy: 40.5\n",
            "Iteration 300, Epoch 1, Loss: 1.9978175163269043, Accuracy: 34.08949279785156, Val Loss: 1.8381661176681519, Val Accuracy: 38.80000305175781\n",
            "Iteration 400, Epoch 1, Loss: 1.9315049648284912, Accuracy: 35.879051208496094, Val Loss: 1.721449851989746, Val Accuracy: 42.79999923706055\n",
            "Iteration 500, Epoch 1, Loss: 1.8863307237625122, Accuracy: 36.94485855102539, Val Loss: 1.6466484069824219, Val Accuracy: 43.599998474121094\n",
            "Iteration 600, Epoch 1, Loss: 1.8551926612854004, Accuracy: 37.89517593383789, Val Loss: 1.673884391784668, Val Accuracy: 43.20000076293945\n",
            "Iteration 700, Epoch 1, Loss: 1.8290902376174927, Accuracy: 38.56990051269531, Val Loss: 1.634737491607666, Val Accuracy: 44.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32, 32, 3)\n",
        "\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLVjxZildPYe",
        "outputId": "8a4d1dad-b9fc-4523-c44d-9708ed49d211"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_5')>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConvNet(tf.keras.Model):\n",
        "    def __init__(self, channel_1, channel_2, channel_3, num_classes):\n",
        "        super(CustomConvNet, self).__init__()\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "      \n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = channel_1, kernel_size = (3,3), strides = (1,1),\n",
        "                                          activation='relu',padding='valid',kernel_initializer=initializer)\n",
        "        # self.drop_out = tf.keras.layers.Dropout(rate = 0.8)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.drop_out1 = tf.keras.layers.Dropout(rate = 0.2)\n",
        "        self.max_pool1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = channel_2, kernel_size = (7,7), strides = (1,1),\n",
        "                                          activation='relu',padding='valid',kernel_initializer=initializer)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.drop_out2 = tf.keras.layers.Dropout(rate = 0.2)\n",
        "        self.max_pool2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = channel_3, kernel_size = (5,5), strides = (1,1),\n",
        "                                        activation='relu',padding='valid',kernel_initializer=initializer)\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.max_pool3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "        self.drop_out3 = tf.keras.layers.Dropout(rate = 0.5)\n",
        "        self.fc = tf.keras.layers.Dense(num_classes,kernel_initializer=initializer)\n",
        "        self.global_avg = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.softmax = tf.keras.layers.Softmax()   \n",
        "\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "    \n",
        "    def call(self, input_tensor, training=False):\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        x = tf.pad(input_tensor, [[0,0], [2,2], [2,2], [0,0]], 'CONSTANT')\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.drop_out1(x)\n",
        "        x = self.max_pool1(x)\n",
        "        x = tf.pad(x, [[0,0], [1,1], [1,1], [0,0]], 'CONSTANT')\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.drop_out2(x)\n",
        "        x = self.max_pool2(x)\n",
        "        x = tf.pad(x, [[0,0], [1,1], [1,1], [0,0]], 'CONSTANT')\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.drop_out3(x)\n",
        "        x = self.max_pool3(x)        \n",
        "        #x = self.flatten(x)\n",
        "        x = self.global_avg(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        # pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "        return x\n",
        "\n",
        "\n",
        "print_every = 700\n",
        "num_epochs = 10\n",
        "\n",
        "channel_1, channel_2, channel_3, num_classes = 256, 112, 64, 10\n",
        "\n",
        "def model_init_fn():\n",
        "    mode = None\n",
        "    model = CustomConvNet(channel_1, channel_2, channel_3, num_classes)\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    learning_rate = 1e-3\n",
        "    return tf.keras.optimizers.Adam(learning_rate) \n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xw4DOC0jwlY",
        "outputId": "26609723-3d1b-4609-8f5f-e4178855ecd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 4.229311943054199, Accuracy: 14.0625, Val Loss: 7.876084327697754, Val Accuracy: 10.899999618530273\n",
            "Iteration 700, Epoch 1, Loss: 1.3885812759399414, Accuracy: 51.627140045166016, Val Loss: 1.1855409145355225, Val Accuracy: 59.500003814697266\n",
            "Iteration 1400, Epoch 2, Loss: 0.9259873032569885, Accuracy: 67.67716217041016, Val Loss: 0.9837809205055237, Val Accuracy: 66.9000015258789\n",
            "Iteration 2100, Epoch 3, Loss: 0.7644560933113098, Accuracy: 73.05305480957031, Val Loss: 0.844839334487915, Val Accuracy: 71.69999694824219\n",
            "Iteration 2800, Epoch 4, Loss: 0.6599968671798706, Accuracy: 76.80480194091797, Val Loss: 0.9524750113487244, Val Accuracy: 68.19999694824219\n",
            "Iteration 3500, Epoch 5, Loss: 0.5857861638069153, Accuracy: 79.48011779785156, Val Loss: 0.8167557120323181, Val Accuracy: 73.5999984741211\n",
            "Iteration 4200, Epoch 6, Loss: 0.5185089707374573, Accuracy: 81.69221496582031, Val Loss: 0.8618490099906921, Val Accuracy: 73.29999542236328\n",
            "Iteration 4900, Epoch 7, Loss: 0.47079408168792725, Accuracy: 83.4067611694336, Val Loss: 0.8916566371917725, Val Accuracy: 72.39999389648438\n",
            "Iteration 5600, Epoch 8, Loss: 0.4168827533721924, Accuracy: 84.95684814453125, Val Loss: 0.8277798891067505, Val Accuracy: 72.0\n",
            "Iteration 6300, Epoch 9, Loss: 0.3922768831253052, Accuracy: 85.82008361816406, Val Loss: 0.8234795331954956, Val Accuracy: 73.79999542236328\n",
            "Iteration 7000, Epoch 10, Loss: 0.3436945378780365, Accuracy: 87.74824523925781, Val Loss: 0.7724483609199524, Val Accuracy: 75.9000015258789\n"
          ]
        }
      ]
    }
  ]
}